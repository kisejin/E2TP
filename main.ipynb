{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n","from datasets import Dataset\n","import pandas as pd\n","import numpy as np\n","import random\n","import torch\n","import types\n","import os\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_folders_in_directory(directory_path):\n","    folders_list = [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n","    return folders_list\n","\n","new_directory_path = \"/kaggle/tmp\"\n","os.makedirs(new_directory_path)\n","\n","directory_path = \"/kaggle/\"\n","folders = get_folders_in_directory(directory_path)\n","\n","print(folders)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import display, HTML\n","\n","display(HTML(\"<script>Jupyter.notebook.kernel.execute('config NotebookApp.iopub_msg_rate_limit=10000000000')</script>\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["aste_step1_aspect = \"\"\"$T$ => aspects: [A]\"\"\"\n","aste_step1_opinion = \"\"\"$T$ => opinions: [O]\"\"\"\n","aste_step1_sentiment = \"\"\"$T$ => sentiments: [S]\"\"\"\n","aste_step2_aspect = [\n","    \"\"\"$T$ $Q$ $A$: aspect, opinion, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, sentiment, opinion\"\"\"\n","]\n","aste_step2_opinion = [\n","    \"\"\"$T$ $Q$ $O$: opinion, sentiment, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, aspect, sentiment\"\"\"\n","]\n","aste_step2_sentiment = [\n","    \"\"\"$T$ $Q$ $S$: sentiment, opinion, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, aspect, opinion\"\"\"\n","]\n","\n","tasd_step1_aspect = \"\"\"$T$ => aspects: [A]\"\"\"\n","tasd_step1_category = \"\"\"$T$ => categories: [C]\"\"\"\n","tasd_step1_sentiment = \"\"\"$T$ => sentiments: [S]\"\"\"\n","tasd_step2_aspect = [\n","    \"\"\"$T$ $Q$ $A$: aspect, category, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, sentiment, category\"\"\"\n","]\n","tasd_step2_category = [\n","    \"\"\"$T$ $Q$ $C$: category, sentiment, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, aspect, sentiment\"\"\"\n","]\n","tasd_step2_sentiment = [\n","    \"\"\"$T$ $Q$ $S$: sentiment, category, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, aspect, category\"\"\"\n","]\n","\n","asqp_step1_aspect = \"\"\"$T$ => aspects: [A]\"\"\"\n","asqp_step1_category = \"\"\"$T$ => categories: [C]\"\"\"\n","asqp_step1_opinion = \"\"\"$T$ => opinions: [O]\"\"\"\n","asqp_step1_sentiment = \"\"\"$T$ => sentiments: [S]\"\"\"\n","asqp_step2_aspect = [\n","    \"\"\"$T$ $Q$ $A$: aspect, category, opinion, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, category, sentiment, opinion\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, opinion, sentiment, category\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, opinion, category, sentiment \"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, sentiment, opinion, category\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, sentiment, category, opinion\"\"\"\n","]\n","asqp_step2_category = [\n","    \"\"\"$T$ $Q$ $C$: category, aspect, opinion, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, aspect, sentiment, opinion\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, opinion, sentiment, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, opinion, aspect, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, sentiment, opinion, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, sentiment, aspect, opinion\"\"\"\n","]\n","asqp_step2_opinion = [\n","    \"\"\"$T$ $Q$ $O$: opinion, category, aspect, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, category, sentiment, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, aspect, sentiment, category\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, aspect, category, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, sentiment, aspect, category\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, sentiment, category, aspect\"\"\"\n","]\n","asqp_step2_sentiment = [\n","    \"\"\"$T$ $Q$ $S$: sentiment, category, opinion, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, category, aspect, opinion\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, opinion, aspect, category\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, opinion, category, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, aspect, opinion, category\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, aspect, category, opinion\"\"\"\n","]\n","\n","acos_step1_aspect = \"\"\"$T$ => aspects: [A]\"\"\"\n","acos_step1_category = \"\"\"$T$ => categories: [C]\"\"\"\n","acos_step1_opinion = \"\"\"$T$ => opinions: [O]\"\"\"\n","acos_step1_sentiment = \"\"\"$T$ => sentiments: [S]\"\"\"\n","acos_step2_aspect = [\n","    \"\"\"$T$ $Q$ $A$: aspect, category, opinion, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, category, sentiment, opinion\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, opinion, sentiment, category\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, opinion, category, sentiment \"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, sentiment, opinion, category\"\"\",\n","    \"\"\"$T$ $Q$ $A$: aspect, sentiment, category, opinion\"\"\"\n","]\n","acos_step2_category = [\n","    \"\"\"$T$ $Q$ $C$: category, aspect, opinion, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, aspect, sentiment, opinion\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, opinion, sentiment, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, opinion, aspect, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, sentiment, opinion, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $C$: category, sentiment, aspect, opinion\"\"\"\n","]\n","acos_step2_opinion = [\n","    \"\"\"$T$ $Q$ $O$: opinion, category, aspect, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, category, sentiment, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, aspect, sentiment, category\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, aspect, category, sentiment\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, sentiment, aspect, category\"\"\",\n","    \"\"\"$T$ $Q$ $O$: opinion, sentiment, category, aspect\"\"\"\n","]\n","acos_step2_sentiment = [\n","    \"\"\"$T$ $Q$ $S$: sentiment, category, opinion, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, category, aspect, opinion\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, opinion, aspect, category\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, opinion, category, aspect\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, aspect, opinion, category\"\"\",\n","    \"\"\"$T$ $Q$ $S$: sentiment, aspect, category, opinion\"\"\"\n","]\n","\n","prompts = {\n","    \"aste\": {\n","        \"step1\": {\n","            \"aspect\": aste_step1_aspect,\n","            \"opinion\": aste_step1_opinion,\n","            \"sentiment\": aste_step1_sentiment\n","        },\n","        \"step2\": {\n","            \"aspect\": aste_step2_aspect,\n","            \"opinion\": aste_step2_opinion,\n","            \"sentiment\": aste_step2_sentiment,\n","        }\n","    },\n","    \"tasd\": {\n","        \"step1\": {\n","            \"aspect\": tasd_step1_aspect,\n","            \"category\": tasd_step1_category,\n","            \"sentiment\": tasd_step1_sentiment\n","        },\n","        \"step2\": {\n","            \"aspect\": tasd_step2_aspect,\n","            \"category\": tasd_step2_category,\n","            \"sentiment\": tasd_step2_sentiment,\n","        }\n","    },\n","    \"asqp\": {\n","        \"step1\": {\n","            \"aspect\": asqp_step1_aspect,\n","            \"category\": asqp_step1_category,\n","            \"opinion\": asqp_step1_opinion,\n","            \"sentiment\": asqp_step1_sentiment\n","        },\n","        \"step2\": {\n","            \"aspect\": asqp_step2_aspect,\n","            \"category\": asqp_step2_category,\n","            \"opinion\": asqp_step2_opinion,\n","            \"sentiment\": asqp_step2_sentiment,\n","        }\n","    },\n","    \"acos\": {\n","        \"step1\": {\n","            \"aspect\": acos_step1_aspect,\n","            \"category\": acos_step1_category,\n","            \"opinion\": acos_step1_opinion,\n","            \"sentiment\": acos_step1_sentiment\n","        },\n","        \"step2\": {\n","            \"aspect\": acos_step2_aspect,\n","            \"category\": acos_step2_category,\n","            \"opinion\": acos_step2_opinion,\n","            \"sentiment\": acos_step2_sentiment,\n","        }\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["element_key_list = {\"aste\": [\"aspect\", \"opinion\", \"sentiment\"], \"tasd\": [\"aspect\", \"category\", \"sentiment\"], \"asqp\": [\"aspect\", \"category\", \"opinion\", \"sentiment\"], \"acos\": [\"aspect\", \"category\", \"opinion\", \"sentiment\"]}\n","\n","def get_step1_prompts(task, text):\n","    final_prompts = [prompts[task][\"step1\"][element_key].replace(\"$T$\", text) for element_key in element_key_list[task]]\n","    return final_prompts\n","\n","def get_step2_prompts(status, task, text, aspects, categories=None, opinions=None, sentiments=None):\n","    new_sent = []\n","    target = []\n","    tuples = []\n","    element_list = element_key_list[task]\n","    for element in element_list:\n","        repeated_items = []\n","        if element == \"category\":\n","            element = \"categorie\"\n","        for item in locals()[f\"{element}s\"]:\n","            if item not in repeated_items:\n","                if locals()[f\"{element}s\"].count(item) == 1:\n","                    q = \"->\"\n","                elif locals()[f\"{element}s\"].count(item) >= 2:\n","                    q = \"=>\"\n","                    repeated_items.append(item)\n","\n","                if element == \"categorie\":\n","                    element = \"category\"\n","                if element == \"aspect\":\n","                    mark = \"A\"\n","                elif element == \"category\":\n","                    mark = \"C\"\n","                elif element == \"opinion\":\n","                    mark = \"O\"\n","                elif element == \"sentiment\":\n","                    mark = \"S\"\n","                prompts_list = [prompt for prompt in prompts[task][\"step2\"][element]]\n","                for i in range(len(prompts_list)):\n","                    prompts_list[i] = prompts_list[i].replace(f\"${mark}$\", item)\n","                    prompts_list[i] = prompts_list[i].replace(f\"$Q$\", q)\n","                    prompts_list[i] = prompts_list[i].replace(f\"$T$\", text)\n","                new_sent.extend(prompts_list)\n","                if element == \"category\":\n","                    element = \"categorie\"\n","    if status == \"train\":\n","        for element in element_list:\n","            repeated_items = []\n","            if element == \"category\":\n","                element = \"categorie\"\n","            for item in locals()[f\"{element}s\"]:\n","                if item not in repeated_items:\n","                    index = locals()[f\"{element}s\"].index(item)\n","                    if task == \"aste\":\n","                        if element == \"aspect\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {opinions[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {opinions[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {opinions[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {sentiments[index]}, {opinions[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                repeated_items.append(item)\n","                        elif element == \"opinion\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {sentiments[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {sentiments[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {sentiments[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {aspects[index]}, {sentiments[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                repeated_items.append(item)\n","                        elif element == \"sentiment\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {opinions[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {opinions[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {opinions[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {aspects[index]}, {opinions[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                repeated_items.append(item)\n","                    elif task == \"tasd\":\n","                        if element == \"aspect\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {categories[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {categories[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {categories[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {sentiments[index]}, {categories[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                repeated_items.append(item)\n","                        elif element == \"categorie\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {sentiments[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {sentiments[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {sentiments[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {aspects[index]}, {sentiments[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                repeated_items.append(item)\n","                        elif element == \"sentiment\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {categories[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {categories[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {categories[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {aspects[index]}, {categories[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                repeated_items.append(item)\n","                    elif task == \"asqp\" or task == \"acos\":\n","                        if element == \"aspect\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {categories[index]}, {opinions[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {categories[index]}, {sentiments[index]}, {opinions[index]}\")\n","                                tuples.append(f\"{item}, {opinions[index]}, {sentiments[index]}, {categories[index]}\")\n","                                tuples.append(f\"{item}, {opinions[index]}, {categories[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {opinions[index]}, {categories[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {categories[index]}, {opinions[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {categories[index]}, {opinions[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {categories[index]}, {sentiments[index]}, {opinions[index]}\" for index in indexes]\n","                                _tuple3 = [f\"{item}, {opinions[index]}, {sentiments[index]}, {categories[index]}\" for index in indexes]\n","                                _tuple4 = [f\"{item}, {opinions[index]}, {categories[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple5 = [f\"{item}, {sentiments[index]}, {opinions[index]}, {categories[index]}\" for index in indexes]\n","                                _tuple6 = [f\"{item}, {sentiments[index]}, {categories[index]}, {opinions[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                tuples.append(\"; \".join(_tuple3))\n","                                tuples.append(\"; \".join(_tuple4))\n","                                tuples.append(\"; \".join(_tuple5))\n","                                tuples.append(\"; \".join(_tuple6))\n","                                repeated_items.append(item)\n","                        elif element == \"categorie\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {aspects[index]}, {opinions[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {sentiments[index]}, {opinions[index]}\")\n","                                tuples.append(f\"{item}, {opinions[index]}, {sentiments[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {opinions[index]}, {aspects[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {opinions[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {aspects[index]}, {opinions[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {aspects[index]}, {opinions[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {aspects[index]}, {sentiments[index]}, {opinions[index]}\" for index in indexes]\n","                                _tuple3 = [f\"{item}, {opinions[index]}, {sentiments[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple4 = [f\"{item}, {opinions[index]}, {aspects[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple5 = [f\"{item}, {sentiments[index]}, {opinions[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple6 = [f\"{item}, {sentiments[index]}, {aspects[index]}, {opinions[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                tuples.append(\"; \".join(_tuple3))\n","                                tuples.append(\"; \".join(_tuple4))\n","                                tuples.append(\"; \".join(_tuple5))\n","                                tuples.append(\"; \".join(_tuple6))\n","                                repeated_items.append(item)\n","                        elif element == \"opinion\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {categories[index]}, {aspects[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {categories[index]}, {sentiments[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {sentiments[index]}, {categories[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {categories[index]}, {sentiments[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {aspects[index]}, {categories[index]}\")\n","                                tuples.append(f\"{item}, {sentiments[index]}, {categories[index]}, {aspects[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {categories[index]}, {aspects[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {categories[index]}, {sentiments[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple3 = [f\"{item}, {aspects[index]}, {sentiments[index]}, {categories[index]}\" for index in indexes]\n","                                _tuple4 = [f\"{item}, {aspects[index]}, {categories[index]}, {sentiments[index]}\" for index in indexes]\n","                                _tuple5 = [f\"{item}, {sentiments[index]}, {aspects[index]}, {categories[index]}\" for index in indexes]\n","                                _tuple6 = [f\"{item}, {sentiments[index]}, {categories[index]}, {aspects[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                tuples.append(\"; \".join(_tuple3))\n","                                tuples.append(\"; \".join(_tuple4))\n","                                tuples.append(\"; \".join(_tuple5))\n","                                tuples.append(\"; \".join(_tuple6))\n","                                repeated_items.append(item)\n","                        elif element == \"sentiment\":\n","                            if locals()[f\"{element}s\"].count(item) == 1:\n","                                tuples.append(f\"{item}, {categories[index]}, {opinions[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {categories[index]}, {aspects[index]}, {opinions[index]}\")\n","                                tuples.append(f\"{item}, {opinions[index]}, {aspects[index]}, {categories[index]}\")\n","                                tuples.append(f\"{item}, {opinions[index]}, {categories[index]}, {aspects[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {opinions[index]}, {categories[index]}\")\n","                                tuples.append(f\"{item}, {aspects[index]}, {categories[index]}, {opinions[index]}\")\n","                            else:\n","                                indexes = [index for index, value in enumerate(locals()[f\"{element}s\"]) if value == item]\n","                                _tuple1 = [f\"{item}, {categories[index]}, {opinions[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple2 = [f\"{item}, {categories[index]}, {aspects[index]}, {opinions[index]}\" for index in indexes]\n","                                _tuple3 = [f\"{item}, {opinions[index]}, {aspects[index]}, {categories[index]}\" for index in indexes]\n","                                _tuple4 = [f\"{item}, {opinions[index]}, {categories[index]}, {aspects[index]}\" for index in indexes]\n","                                _tuple5 = [f\"{item}, {aspects[index]}, {opinions[index]}, {categories[index]}\" for index in indexes]\n","                                _tuple6 = [f\"{item}, {aspects[index]}, {categories[index]}, {opinions[index]}\" for index in indexes]\n","                                tuples.append(\"; \".join(_tuple1))\n","                                tuples.append(\"; \".join(_tuple2))\n","                                tuples.append(\"; \".join(_tuple3))\n","                                tuples.append(\"; \".join(_tuple4))\n","                                tuples.append(\"; \".join(_tuple5))\n","                                tuples.append(\"; \".join(_tuple6))\n","                                repeated_items.append(item)\n","        target.extend(tuples)\n","        return new_sent, target\n","    elif status == \"inference\":\n","        return new_sent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["senttag2opinion = {'pos': 'positive', 'neg': 'negative', 'neu': 'neutral'}\n","sentword2opinion = {'positive': 'positive', 'negative': 'negative', 'neutral': 'neutral'}\n","\n","rest_aspect_general_cate_list = [\n","    'restaurant', 'ambience', 'location', 'food', 'service', 'drinks'\n","]\n","\n","rest_aspect_sub_cate_list = [\n","    'style_options', 'quality', 'prices', 'miscellaneous', 'general'\n","]\n","\n","laptop_aspect_general_cate_list = [\n","    'display', 'out_of_scope', 'power_supply', 'warranty', 'keyboard', 'os', 'memory', 'multimedia_devices', 'laptop', 'shipping', 'graphics', 'battery', 'company', 'ports', 'motherboard', 'optical_drives', 'software', 'fans&cooling', 'hard_disc', 'cpu', 'hardware', 'mouse', 'support'\n","]\n","\n","laptop_aspect_sub_cate_list = [\n","    'quality', 'general', 'price', 'design_features', 'miscellaneous', 'portability', 'connectivity', 'usability', 'operation_performance'\n","]\n","\n","general_cate_list = {\n","    \"rest14\": rest_aspect_general_cate_list,\n","    \"rest15\": rest_aspect_general_cate_list,\n","    \"rest\": rest_aspect_general_cate_list,\n","    \"rest16\": rest_aspect_general_cate_list,\n","    \"laptop\": laptop_aspect_general_cate_list,\n","    \"laptop14\": laptop_aspect_general_cate_list\n","}\n","\n","sub_cate_list = {\n","    \"rest14\": rest_aspect_sub_cate_list,\n","    \"rest15\": rest_aspect_sub_cate_list,\n","    \"rest\": rest_aspect_sub_cate_list,\n","    \"rest16\": rest_aspect_sub_cate_list,\n","    \"laptop\": laptop_aspect_sub_cate_list,\n","    \"laptop14\": laptop_aspect_sub_cate_list\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["main_prompt_marks = {\n","    \"aste\": '[A] [O] [S]',\n","    \"tasd\": '[A] [C] [S]',\n","    \"asqp\": '[A] [C] [O] [S]',\n","    \"acos\": '[A] [C] [O] [S]'\n","}\n","\n","def get_task_prompt_marks(task):\n","    return main_prompt_marks[task]\n","\n","def parse_aste_tuple(_tuple, sent):\n","\n","    if isinstance(_tuple[0], str):\n","        res = _tuple\n","\n","    elif isinstance(_tuple[0], list):\n","        start_idx = _tuple[0][0]\n","        end_idx = _tuple[0][-1] if len(_tuple[0]) > 1 else start_idx\n","        at = ' '.join(sent[start_idx:end_idx + 1])\n","        start_idx = _tuple[1][0]\n","        end_idx = _tuple[1][-1] if len(_tuple[1]) > 1 else start_idx\n","        ot = ' '.join(sent[start_idx:end_idx + 1])\n","        res = [at, ot, _tuple[2]]\n","    else:\n","        print(_tuple)\n","        raise NotImplementedError\n","    return res\n","\n","def get_task_tuple(_tuple, task):\n","    if task == \"aste\":\n","        at, ot, sp = _tuple\n","        ac = None\n","    elif task == \"tasd\":\n","        at, ac, sp = _tuple\n","        ot = None\n","    elif task in [\"asqp\", \"acos\"]:\n","        at, ac, sp, ot = _tuple\n","    else:\n","        raise NotImplementedError\n","\n","    if sp:\n","        sp = sentword2opinion[sp.lower()] if sp in sentword2opinion \\\n","            else senttag2opinion[sp.lower()]\n","    if at and at.lower() == 'null':\n","        at = 'it'\n","\n","    return at, ac, sp, ot\n","\n","def generate_element_list(_tuple, marks, task, final_gold_output):\n","    at, ac, sp, ot = get_task_tuple(_tuple, task)\n","    element_dict = {\"[A]\": at, \"[O]\": ot, \"[C]\": ac, \"[S]\": sp}\n","    if final_gold_output == False:\n","        return [f\"{element_dict[key]}\" for key in marks.split(\" \")]\n","    else:\n","        return [f\"{key} {element_dict[key]}\" for key in marks.split(\" \")]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_para_targets(sents, labels, task, step, final_gold_output):\n","    if final_gold_output == False:\n","        targets = []\n","        new_sents = []\n","        marks = get_task_prompt_marks(task)\n","        for i in range(len(sents)):\n","            label = labels[i]\n","            cur_sent = sents[i]\n","            cur_sent_str = \" \".join(cur_sent)\n","            if task == 'aste':\n","                assert len(label[0]) == 3\n","                parsed_label = []\n","                for _tuple in label:\n","                    parsed_tuple = parse_aste_tuple(_tuple, sents[i])\n","                    parsed_label.append(parsed_tuple)\n","                label = parsed_label\n","            label_pos = {}\n","            for _tuple in label:\n","                at, ac, sp, ot = get_task_tuple(_tuple, task)\n","                at_pos = cur_sent_str.find(at) if at else -1\n","                ot_pos = cur_sent_str.find(ot) if ot else -1\n","                last_pos = max(at_pos, ot_pos)\n","                last_pos = 1e4 if last_pos < 0 else last_pos\n","                label_pos[tuple(_tuple)] = last_pos\n","            new_label = [\n","                list(k)\n","                for k, _ in sorted(label_pos.items(), key=lambda x: x[1])\n","            ]\n","            label = new_label\n","            main_target = [generate_element_list(_tuple, marks, task, False) for _tuple in label]\n","            main_sent = \" \".join(cur_sent)\n","            aspects, categories, opinions, sentiments = [], [], [], []\n","            target = []\n","            new_sent = []\n","            if task == \"aste\":\n","                for tar in main_target:\n","                    aspects.append(tar[0])\n","                    opinions.append(tar[1])\n","                    sentiments.append(tar[2])\n","                target.append(\"[A] \"+\"; \".join(aspects))\n","                target.append(\"[O] \"+\"; \".join(opinions))\n","                target.append(\"[S] \"+\"; \".join(sentiments))\n","            elif task == \"tasd\":\n","                for tar in main_target:\n","                    aspects.append(tar[0])\n","                    categories.append(tar[1])\n","                    sentiments.append(tar[2])\n","                target.append(\"[A] \"+\"; \".join(aspects))\n","                target.append(\"[C] \"+\"; \".join(categories))\n","                target.append(\"[S] \"+\"; \".join(sentiments))\n","            elif task == \"asqp\" or task == \"acos\":\n","                for tar in main_target:\n","                    aspects.append(tar[0])\n","                    categories.append(tar[1])\n","                    opinions.append(tar[2])\n","                    sentiments.append(tar[3])\n","                target.append(\"[A] \"+\"; \".join(aspects))\n","                target.append(\"[C] \"+\"; \".join(categories))\n","                target.append(\"[O] \"+\"; \".join(opinions))\n","                target.append(\"[S] \"+\"; \".join(sentiments))\n","            if step == 1:\n","                new_sent = get_step1_prompts(task, main_sent)\n","                targets.extend(target)\n","                new_sents.extend(new_sent)\n","            elif step == 2:\n","                target = []\n","                if task == \"aste\":\n","                    new_sent, target = get_step2_prompts(\"train\", task, main_sent, aspects=aspects, opinions=opinions, sentiments=sentiments)\n","                elif task == \"tasd\":\n","                    new_sent, target = get_step2_prompts(\"train\", task, main_sent, aspects=aspects, categories=categories, sentiments=sentiments)\n","                elif task == \"asqp\" or task == \"acos\":\n","                    new_sent, target = get_step2_prompts(\"train\", task, main_sent, aspects=aspects, categories=categories, opinions=opinions, sentiments=sentiments)\n","                targets.extend(target)\n","                new_sents.extend(new_sent)\n","        return new_sents, targets\n","    else:\n","        targets = []\n","        marks = get_task_prompt_marks(task)\n","        for i in range(len(sents)):\n","            label = labels[i]\n","            cur_sent = sents[i]\n","            cur_sent_str = \" \".join(cur_sent)\n","            if task == 'aste':\n","                assert len(label[0]) == 3\n","                parsed_label = []\n","                for _tuple in label:\n","                    parsed_tuple = parse_aste_tuple(_tuple, sents[i])\n","                    parsed_label.append(parsed_tuple)\n","                label = parsed_label\n","            label_pos = {}\n","            for _tuple in label:\n","                at, ac, sp, ot = get_task_tuple(_tuple, task)\n","                at_pos = cur_sent_str.find(at) if at else -1\n","                ot_pos = cur_sent_str.find(ot) if ot else -1\n","                last_pos = max(at_pos, ot_pos)\n","                last_pos = 1e4 if last_pos < 0 else last_pos\n","                label_pos[tuple(_tuple)] = last_pos\n","            new_label = [\n","                list(k)\n","                for k, _ in sorted(label_pos.items(), key=lambda x: x[1])\n","            ]\n","            label = new_label\n","            target = [\n","                \" [SSEP] \".join([\n","                    \" \".join(generate_element_list(_tuple, marks, task, True))\n","                    for _tuple in label\n","                ])\n","            ]\n","            targets.extend(target)\n","        return targets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_line_examples_from_file(data_path, task):\n","    tasks, data_names, sents, labels = [], [], [], []\n","    with open(data_path, 'r', encoding='UTF-8') as fp:\n","        if task != \"unified\":\n","            words, labels = [], []\n","            for line in fp:\n","                line = line.strip()\n","                line = line.lower()\n","                if line != '':\n","                    words, tuples = line.split('####')\n","                    sents.append(words.split())\n","                    labels.append(eval(tuples))\n","            return sents, labels\n","        else:\n","            for line in fp:\n","                line = line.strip()\n","                line = line.lower()\n","                if line != '':\n","                    parts = line.split('\\t')\n","                    tasks.append(parts[0])\n","                    data_names.append(parts[1])\n","                    new_part = parts[2].split(\"####\")\n","                    sents.append(new_part[0].strip().split())\n","                    labels.append(eval(new_part[1].strip()))\n","            return tasks, data_names, sents, labels\n","\n","\n","def get_transformed_io(data_path, task, step, final_gold_output=False, seed=None, percentage=None):\n","    sents, labels = read_line_examples_from_file(data_path, task)\n","    inputs = [s.copy() for s in sents]\n","    if seed is not None and percentage is not None:\n","        random.seed(seed)\n","        num_sample = int(len(inputs) * percentage)\n","        sample_indices = random.sample(list(range(0, len(inputs))), num_sample)\n","        inputs = [inputs[i] for i in sample_indices]\n","        labels = [labels[i] for i in sample_indices]\n","    if final_gold_output==False:\n","        new_inputs, targets = get_para_targets(inputs, labels, task, step, final_gold_output)\n","        return new_inputs, targets\n","    else:\n","        targets = get_para_targets(inputs, labels, task, step, final_gold_output)\n","        return targets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["parent_directory = \"/kaggle/input/e2tp-absa/\"\n","single_tasks = {\"tasd\": [\"rest15\", \"rest16\"], \"asqp\": [\"rest15\", \"rest16\"], \"acos\": [\"laptop16\", \"rest16\"], \"aste\": [\"laptop14\", \"rest14\", \"rest15\", \"rest16\", \"laptop14-rest14\", \"laptop14-rest15\", \"laptop14-rest16\", \"rest14-laptop14\", \"rest15-laptop14\", \"rest16-laptop14\"]}\n","\n","data_step1 = {}\n","for task, data_names in single_tasks.items():\n","    for data_name in data_names:\n","        train_inputs, train_targets = get_transformed_io(f\"{parent_directory}{task}/{data_name}/train.txt\", task, step=1, final_gold_output=False)\n","        dev_inputs, dev_targets = get_transformed_io(f\"{parent_directory}{task}/{data_name}/dev.txt\", task, step=1, final_gold_output=False)\n","        test_inputs, test_targets = get_transformed_io(f\"{parent_directory}{task}/{data_name}/test.txt\", task, step=1, final_gold_output=False)\n","        data_step1[f\"{task}-{data_name}\"] = [[train_inputs, train_targets], [dev_inputs, dev_targets], [test_inputs, test_targets]]\n","\n","data_step2 = {}\n","for task, data_names in single_tasks.items():\n","    for data_name in data_names:\n","        train_inputs, train_targets = get_transformed_io(f\"{parent_directory}{task}/{data_name}/train.txt\", task, step=2, final_gold_output=False)\n","        dev_inputs, dev_targets = get_transformed_io(f\"{parent_directory}{task}/{data_name}/dev.txt\", task, step=2, final_gold_output=False)\n","        test_targets = get_transformed_io(f\"{parent_directory}{task}/{data_name}/test.txt\", task, step=2, final_gold_output=True)\n","        data_step2[f\"{task}-{data_name}\"] = [[train_inputs, train_targets], [dev_inputs, dev_targets], [test_targets]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_spans_para(seq, seq_type):\n","    quads = []\n","    sents = [s.strip() for s in seq.split('[SSEP]')]\n","    for s in sents:\n","        try:\n","            tok_list = [\"[C]\", \"[S]\", \"[A]\", \"[O]\"]\n","\n","            for tok in tok_list:\n","                if tok not in s:\n","                    s += \" {} null\".format(tok)\n","            index_ac = s.index(\"[C]\")\n","            index_sp = s.index(\"[S]\")\n","            index_at = s.index(\"[A]\")\n","            index_ot = s.index(\"[O]\")\n","\n","            combined_list = [index_ac, index_sp, index_at, index_ot]\n","            arg_index_list = list(np.argsort(combined_list))\n","\n","            result = []\n","            for i in range(len(combined_list)):\n","                start = combined_list[i] + 4\n","                sort_index = arg_index_list.index(i)\n","                if sort_index < 3:\n","                    next_ = arg_index_list[sort_index + 1]\n","                    re = s[start:combined_list[next_]]\n","                else:\n","                    re = s[start:]\n","                result.append(re.strip())\n","\n","            ac, sp, at, ot = result\n","\n","            if at.lower() == 'it':\n","                at = 'null'\n","        except ValueError:\n","            try:\n","                print(f'In {seq_type} seq, cannot decode: {s}')\n","                pass\n","            except UnicodeEncodeError:\n","                print(f'In {seq_type} seq, a string cannot be decoded')\n","                pass\n","            ac, at, sp, ot = '', '', '', ''\n","\n","        quads.append((ac, at, sp, ot))\n","\n","    return quads\n","\n","\n","def compute_f1_scores(pred_pt, gold_pt, verbose=True):\n","    \"\"\"\n","    Function to compute F1 scores with pred and gold quads\n","    The input needs to be already processed\n","    \"\"\"\n","    # number of true postive, gold standard, predictions\n","    n_tp, n_gold, n_pred = 0, 0, 0\n","\n","    for i in range(len(pred_pt)):\n","        n_gold += len(gold_pt[i])\n","        n_pred += len(pred_pt[i])\n","\n","        for t in pred_pt[i]:\n","            if t in gold_pt[i]:\n","                n_tp += 1\n","    precision = float(n_tp) / float(n_pred) if n_pred != 0 else 0\n","    recall = float(n_tp) / float(n_gold) if n_gold != 0 else 0\n","    f1 = 2 * precision * recall / (\n","        precision + recall) if precision != 0 or recall != 0 else 0\n","    scores = {\n","        'precision': precision * 100,\n","        'recall': recall * 100,\n","        'f1': f1 * 100\n","    }\n","\n","    return scores\n","\n","\n","def compute_scores(pred_seqs, gold_seqs, verbose=True):\n","    \"\"\"\n","    Compute model performance\n","    \"\"\"\n","    assert len(pred_seqs) == len(gold_seqs), (len(pred_seqs), len(gold_seqs))\n","    num_samples = len(gold_seqs)\n","\n","    all_labels, all_preds = [], []\n","\n","    for i in range(num_samples):\n","        gold_list = extract_spans_para(gold_seqs[i], 'gold')\n","        pred_list = extract_spans_para(pred_seqs[i], 'pred')\n","        all_labels.append(gold_list)\n","        all_preds.append(pred_list)\n","\n","    scores = compute_f1_scores(all_preds, all_labels)\n","\n","    return scores, all_labels, all_preds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_text(input_string):\n","    return input_string.split(\"=>\")[0].strip()\n","\n","def find_current_order(input_prompt):\n","    if input_prompt.find(\": aspect, opinion, sentiment\") != -1 and \"sentiment,\" not in input_prompt:\n","        return [\"[A]\", \"[O]\", \"[S]\"]\n","    elif input_prompt.find(\": aspect, sentiment, opinion\") != -1 and \"opinion,\" not in input_prompt:\n","        return [\"[A]\", \"[S]\", \"[O]\"]\n","    elif input_prompt.find(\": opinion, sentiment, aspect\") != -1 and \"aspect,\" not in input_prompt:\n","        return [\"[O]\", \"[S]\", \"[A]\"]\n","    elif input_prompt.find(\": opinion, aspect, sentiment\") != -1 and \"sentiment,\" not in input_prompt:\n","        return [\"[O]\", \"[A]\", \"[S]\"]\n","    elif input_prompt.find(\": sentiment, opinion, aspect\") != -1 and \"aspect,\" not in input_prompt:\n","        return [\"[S]\", \"[O]\", \"[A]\"]\n","    elif input_prompt.find(\": sentiment, aspect, opinion\") != -1 and \"opinion,\" not in input_prompt:\n","        return [\"[S]\", \"[A]\", \"[O]\"]\n","\n","    elif input_prompt.find(\": aspect, category, sentiment\") != -1 and \"sentiment,\" not in input_prompt:\n","        return [\"[A]\", \"[C]\", \"[S]\"]\n","    elif input_prompt.find(\": aspect, sentiment, category\") != -1 and \"category,\" not in input_prompt:\n","        return [\"[A]\", \"[S]\", \"[C]\"]\n","    elif input_prompt.find(\": category, sentiment, aspect\") != -1 and \"aspect,\" not in input_prompt:\n","        return [\"[C]\", \"[S]\", \"[A]\"]\n","    elif input_prompt.find(\": category, aspect, sentiment\") != -1 and \"sentiment,\" not in input_prompt:\n","        return [\"[C]\", \"[A]\", \"[S]\"]\n","    elif input_prompt.find(\": sentiment, category, aspect\") != -1 and \"aspect,\" not in input_prompt:\n","        return [\"[S]\", \"[C]\", \"[A]\"]\n","    elif input_prompt.find(\": sentiment, aspect, category\") != -1 and \"category,\" not in input_prompt:\n","        return [\"[S]\", \"[A]\", \"[C]\"]\n","\n","    elif input_prompt.find(\": aspect, category, opinion, sentiment\") != -1:\n","        return [\"[A]\", \"[C]\", \"[O]\", \"[S]\"]\n","    elif input_prompt.find(\": aspect, category, sentiment, opinion\") != -1:\n","        return [\"[A]\", \"[C]\", \"[S]\", \"[O]\"]\n","    elif input_prompt.find(\": aspect, opinion, sentiment, category\") != -1:\n","        return [\"[A]\", \"[O]\", \"[S]\", \"[C]\"]\n","    elif input_prompt.find(\": aspect, opinion, category, sentiment\") != -1:\n","        return [\"[A]\", \"[O]\", \"[C]\", \"[S]\"]\n","    elif input_prompt.find(\": aspect, sentiment, opinion, category\") != -1:\n","        return [\"[A]\", \"[S]\", \"[O]\", \"[C]\"]\n","    elif input_prompt.find(\": aspect, sentiment, category, opinion\") != -1:\n","        return [\"[A]\", \"[S]\", \"[C]\", \"[O]\"]\n","\n","    elif input_prompt.find(\"category, aspect, opinion, sentiment\") != -1:\n","        return [\"[C]\", \"[A]\", \"[O]\", \"[S]\"]\n","    elif input_prompt.find(\"category, aspect, sentiment, opinion\") != -1:\n","        return [\"[C]\", \"[A]\", \"[S]\", \"[O]\"]\n","    elif input_prompt.find(\"category, opinion, sentiment, aspect\") != -1:\n","        return [\"[C]\", \"[O]\", \"[S]\", \"[A]\"]\n","    elif input_prompt.find(\"category, opinion, aspect, sentiment\") != -1:\n","        return [\"[C]\", \"[O]\", \"[A]\", \"[S]\"]\n","    elif input_prompt.find(\"category, sentiment, opinion, aspect\") != -1:\n","        return [\"[C]\", \"[S]\", \"[O]\", \"[A]\"]\n","    elif input_prompt.find(\"category, sentiment, aspect, opinion\") != -1:\n","        return [\"[C]\", \"[S]\", \"[A]\", \"[O]\"]\n","\n","    elif input_prompt.find(\"opinion, category, aspect, sentiment\") != -1:\n","        return [\"[O]\", \"[C]\", \"[A]\", \"[S]\"]\n","    elif input_prompt.find(\"opinion, category, sentiment, aspect\") != -1:\n","        return [\"[O]\", \"[C]\", \"[S]\", \"[A]\"]\n","    elif input_prompt.find(\"opinion, aspect, sentiment, category\") != -1:\n","        return [\"[O]\", \"[A]\", \"[S]\", \"[C]\"]\n","    elif input_prompt.find(\"opinion, aspect, category, sentiment\") != -1:\n","        return [\"[O]\", \"[A]\", \"[C]\", \"[S]\"]\n","    elif input_prompt.find(\"opinion, sentiment, aspect, category\") != -1:\n","        return [\"[O]\", \"[S]\", \"[A]\", \"[C]\"]\n","    elif input_prompt.find(\"opinion, sentiment, category, aspect\") != -1:\n","        return [\"[O]\", \"[S]\", \"[C]\", \"[A]\"]\n","\n","    elif input_prompt.find(\"sentiment, category, opinion, aspect\") != -1:\n","        return [\"[S]\", \"[C]\", \"[O]\", \"[A]\"]\n","    elif input_prompt.find(\"sentiment, category, aspect, opinion\") != -1:\n","        return [\"[S]\", \"[C]\", \"[A]\", \"[O]\"]\n","    elif input_prompt.find(\"sentiment, opinion, aspect, category\") != -1:\n","        return [\"[S]\", \"[O]\", \"[A]\", \"[C]\"]\n","    elif input_prompt.find(\"sentiment, opinion, category, aspect\") != -1:\n","        return [\"[S]\", \"[O]\", \"[C]\", \"[A]\"]\n","    elif input_prompt.find(\"sentiment, aspect, opinion, category\") != -1:\n","        return [\"[S]\", \"[A]\", \"[O]\", \"[C]\"]\n","    elif input_prompt.find(\"sentiment, aspect, category, opinion\") != -1:\n","        return [\"[S]\", \"[A]\", \"[C]\", \"[O]\"]\n","    else:\n","        raise Exception(\"!!\")\n","\n","def extract_elements(text, char, remove_par=True):\n","    if remove_par == True:\n","        text = text.replace(\"(\", \"\")\n","        text = text.replace(\")\", \"\")\n","    texts = text.split(char)\n","    return [text.strip() for text in texts if text.strip() != \"\"]\n","\n","def set_default_order(current_order, goal_order, _tuple):\n","    if len(extract_elements(_tuple.replace(\";\", \",\"), \",\")) == len(current_order) * len(extract_elements(_tuple, \";\")):\n","        if _tuple.find(\";\") != -1:\n","            _tuple = extract_elements(_tuple, \";\", remove_par = False)\n","            for i in range(len(_tuple)):\n","                _tuple[i] = extract_elements(_tuple[i], \",\")\n","                for j in range(len(_tuple[i])):\n","                    _tuple[i][j] = [current_order[j], _tuple[i][j]]\n","                index_dict = {value: index for index, value in enumerate(goal_order)}\n","                _tuple[i] = sorted(_tuple[i], key=lambda x: index_dict[x[0]])\n","                for j in range(len(_tuple[i])):\n","                    _tuple[i][j] = \" \".join(_tuple[i][j])\n","                _tuple[i] = \" \".join(_tuple[i])\n","            return \" [SSEP] \".join(_tuple)\n","        else:\n","            _tuple = extract_elements(_tuple, \",\")\n","            for j in range(len(_tuple)):\n","                _tuple[j] = [current_order[j], _tuple[j]]\n","            index_dict = {value: index for index, value in enumerate(goal_order)}\n","            _tuple = sorted(_tuple, key=lambda x: index_dict[x[0]])\n","            for j in range(len(_tuple)):\n","                _tuple[j] = \" \".join(_tuple[j])\n","            _tuple = \" \".join(_tuple)\n","            return _tuple\n","    else:\n","        flag = 0\n","        _lis = _tuple.split(\"; \")\n","        for i in range(len(_lis)):\n","            if len(extract_elements(_lis[i].replace(\";\", \",\"), \",\")) == len(current_order) * len(extract_elements(_lis[i], \";\")) != \"\":\n","                _lis[i] = set_default_order(current_order, goal_order, _lis[i])\n","                flag = 1\n","        if flag == 1:\n","            return \"; \".join(_lis)\n","        print(_tuple)\n","        return \"\"\n","\n","def inference(model_path_step1, model_path_step2, task_name, data_name, full_or_diet, depth):\n","    global data_step1\n","    global data_step2\n","    outputs_step1, outputs_step2 = [], []\n","    prompt_quantities_step2 = []\n","    device1 = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","    device2 = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n","    tokenizer_step1 = AutoTokenizer.from_pretrained(model_path_step1)\n","    model_step1 = AutoModelForSeq2SeqLM.from_pretrained(model_path_step1).to(device1)\n","    tokenizer_step2 = AutoTokenizer.from_pretrained(model_path_step2)\n","    model_step2 = AutoModelForSeq2SeqLM.from_pretrained(model_path_step2).to(device2)\n","    batch_size = 100\n","    prompt_batches_step1 = [data_step1[f\"{task_name}-{data_name}\"][2][0][i:i+batch_size] for i in range(0, len(data_step1[f\"{task_name}-{data_name}\"][2][0]), batch_size)]\n","    torch.cuda.empty_cache()\n","    for batch in prompt_batches_step1:\n","        inputs = tokenizer_step1(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=200)\n","        inputs = {key: tensor.to(device1) for key, tensor in inputs.items()}\n","        outputs = model_step1.generate(**inputs, max_new_tokens=256)\n","        batch_responses = [tokenizer_step1.decode(output, skip_special_tokens=True) for output in outputs]\n","        outputs_step1.extend(batch_responses)\n","    texts = []\n","    prompts_step1 = [data for data in data_step1[f\"{task_name}-{data_name}\"][2][0]]\n","    prompts_step2 = []\n","    for prompt in prompts_step1:\n","        texts.append(extract_text(prompt))\n","    if task_name == \"aste\":\n","        i = 0\n","        while i < len(outputs_step1):\n","            aspects, opinions, sentiments = [], [], []\n","            outputs_step1[i] = outputs_step1[i].replace(\"[A] \", \"\")\n","            for item in outputs_step1[i].split(\"; \"):\n","                aspects.append(item)\n","            outputs_step1[i+1] = outputs_step1[i+1].replace(\"[O] \", \"\")\n","            for item in outputs_step1[i+1].split(\"; \"):\n","                opinions.append(item)\n","            outputs_step1[i+2] = outputs_step1[i+2].replace(\"[S] \", \"\")\n","            for item in outputs_step1[i+2].split(\"; \"):\n","                sentiments.append(item)\n","            prompt_list = get_step2_prompts(\"inference\", task_name, texts[i], aspects = aspects, opinions = opinions, sentiments = sentiments)\n","            prompts_step2.extend(prompt_list)\n","            prompt_quantities_step2.append(len(prompt_list))\n","            i += 3\n","    elif task_name == \"tasd\":\n","        i = 0\n","        while i < len(outputs_step1):\n","            aspects, categories, sentiments = [], [], []\n","            outputs_step1[i] = outputs_step1[i].replace(\"[A] \", \"\")\n","            for item in outputs_step1[i].split(\"; \"):\n","                aspects.append(item)\n","            outputs_step1[i+1] = outputs_step1[i+1].replace(\"[C] \", \"\")\n","            for item in outputs_step1[i+1].split(\"; \"):\n","                categories.append(item)\n","            outputs_step1[i+2] = outputs_step1[i+2].replace(\"[S] \", \"\")\n","            for item in outputs_step1[i+2].split(\"; \"):\n","                sentiments.append(item)\n","            prompt_list = get_step2_prompts(\"inference\", task_name, texts[i], aspects = aspects, categories = categories, sentiments = sentiments)\n","            prompts_step2.extend(prompt_list)\n","            prompt_quantities_step2.append(len(prompt_list))\n","            i += 3\n","    elif task_name == \"asqp\" or task_name == \"acos\":\n","        i = 0\n","        while i < len(outputs_step1):\n","            aspects, categories, opinions, sentiments = [], [], [], []\n","            outputs_step1[i] = outputs_step1[i].replace(\"[A] \", \"\")\n","            for item in outputs_step1[i].split(\"; \"):\n","                aspects.append(item)\n","            outputs_step1[i+1] = outputs_step1[i+1].replace(\"[C] \", \"\")\n","            for item in outputs_step1[i+1].split(\"; \"):\n","                categories.append(item)\n","            outputs_step1[i+2] = outputs_step1[i+2].replace(\"[O] \", \"\")\n","            for item in outputs_step1[i+2].split(\"; \"):\n","                opinions.append(item)\n","            outputs_step1[i+3] = outputs_step1[i+3].replace(\"[S] \", \"\")\n","            for item in outputs_step1[i+3].split(\"; \"):\n","                sentiments.append(item)\n","            prompt_list = get_step2_prompts(\"inference\", task_name, texts[i], aspects = aspects, categories = categories, opinions = opinions, sentiments = sentiments)\n","            prompts_step2.extend(prompt_list)\n","            prompt_quantities_step2.append(len(prompt_list))\n","            i += 4\n","    batch_size = 200\n","    prompt_batches_step2 = [prompts_step2[i:i+batch_size] for i in range(0, len(prompts_step2), batch_size)]\n","    torch.cuda.empty_cache()\n","    for batch in prompt_batches_step2:\n","        inputs = tokenizer_step2(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=250)\n","        inputs = {key: tensor.to(device2) for key, tensor in inputs.items()}\n","        outputs = model_step2.generate(**inputs, max_new_tokens=512)\n","        batch_responses = [tokenizer_step2.decode(output, skip_special_tokens=True) for output in outputs]\n","        outputs_step2.extend(batch_responses)\n","        \n","    for i in range(len(outputs_step2)):\n","        new_list = outputs_step2[i].split(\"; \")\n","        for j in range(len(new_list)):\n","            new_list[j] = \"(\"+new_list[j]+\")\"\n","        outputs_step2[i] = \"; \".join(new_list)\n","        \n","    tuples = []\n","    current_orders_step2 = []\n","    current_position = 0\n","\n","    for quantity in prompt_quantities_step2:\n","        _tuple = []\n","        current_order = []\n","        for i in range(quantity):\n","            _tuple.append(outputs_step2[current_position])\n","            current_order.append(find_current_order(prompts_step2[current_position]))\n","            current_position += 1\n","        tuples.append(_tuple)\n","        current_orders_step2.append(current_order)\n","\n","    if task_name == \"aste\":\n","        goal_order = [\"[A]\", \"[O]\", \"[S]\"]\n","        threshold = 3\n","        if full_or_diet == \"diet\":\n","            threshold = 1\n","    elif task_name == \"tasd\":\n","        goal_order = [\"[A]\", \"[C]\", \"[S]\"]\n","        threshold = 3\n","        if full_or_diet == \"diet\":\n","            threshold = 1\n","    elif task_name == \"asqp\" or task_name == \"acos\":\n","        goal_order = [\"[A]\", \"[C]\", \"[O]\", \"[S]\"]\n","        threshold = 12\n","        if full_or_diet == \"diet\":\n","            threshold = 2\n","    for i in range(len(tuples)):\n","        for j in range(len(tuples[i])):\n","            current_order = current_orders_step2[i][j]\n","            tuples[i][j] = set_default_order(current_order, goal_order, tuples[i][j])\n","\n","    for i in range(len(tuples)):\n","        aux_list = []\n","        for item in tuples[i]:\n","            if item.find(\"[SSEP]\") != -1:\n","                aux_list.extend(item.split(\" [SSEP] \"))\n","            elif item.strip() != \"\":\n","                aux_list.append(item)\n","\n","        frequency_dict = {}\n","        for item in aux_list:\n","            if item not in frequency_dict.keys():\n","                frequency_dict[item] = 1\n","            else:\n","                frequency_dict[item] += 1\n","        tuples[i] = \" [SSEP] \".join([key for key, value in frequency_dict.items() if value > threshold])\n","        c = 1\n","        while c <= depth:\n","            if tuples[i] == \"\":\n","                tuples[i] = \" [SSEP] \".join([key for key, value in frequency_dict.items() if value > threshold-c])\n","            c += 1\n","    golds = data_step2[f\"{task_name}-{data_name}\"][2][0]\n","    scores, all_labels, all_preds = compute_scores(tuples, golds)\n","    print(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["status = input(\"Choose the Status: \")\n","if status == \"train\":\n","    model_path = input(\"Model Path: \")\n","    train_task_name = input(\"Training Task Name: \")\n","    train_data_name = input(\"Training Data Name: \")\n","    step = int(input(\"Step: \"))\n","    model_seed = int(input(\"Trainer Seed (0 or 42): \"))\n","    if step == 1:\n","        full_or_diet_or_low = \"full\"\n","    elif step == 2:\n","        full_or_diet_or_low = input(\"Full Data or Diet or Low Resource: \")\n","        if full_or_diet_or_low == \"diet\":\n","            random.seed(model_seed)\n","\n","            for element in element_key_list[train_task_name]:\n","                prompts[train_task_name]['step2'][element] = [random.choice(prompts[train_task_name]['step2'][element])]\n","\n","            train_inputs, train_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/train.txt\", train_task_name, step=2, final_gold_output=False)\n","            dev_inputs, dev_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/dev.txt\", train_task_name, step=2, final_gold_output=False)\n","            test_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/test.txt\", train_task_name, step=2, final_gold_output=True)\n","            train_targets = [data_step2[f\"{train_task_name}-{train_data_name}\"][0][1][data_step2[f\"{train_task_name}-{train_data_name}\"][0][0].index(train_input)] for train_input in train_inputs]\n","            dev_targets = [data_step2[f\"{train_task_name}-{train_data_name}\"][1][1][data_step2[f\"{train_task_name}-{train_data_name}\"][1][0].index(dev_input)] for dev_input in dev_inputs]\n","            data_step2[f\"{train_task_name}-{train_data_name}\"] = [[train_inputs, train_targets], [dev_inputs, dev_targets], [test_targets]]\n","\n","        elif full_or_diet_or_low == \"low\":\n","            percentage = int(input(\"Percentage (1 or 2 or 5 or 10): \"))\n","            data_seed = input(\"Data Seed (5 or 10 or 20 or 25): \")\n","            model_seed = data_seed\n","    epoch = int(input(\"Epoch: \"))\n","    huggingface_token = input(\"Huggingface Token: \")\n","    repo_name = input(\"Repository Name: \")\n","elif status == \"inference\":\n","    model_path_step1 = input(\"First Step Model Path in Huggingface: \")\n","    model_path_step2 = input(\"Second Step Model Path in Huggingface: \")\n","    inference_task_name = input(\"Inference Task Name: \")\n","    inference_data_name = input(\"Inference Data Name: \")\n","    full_or_diet = input(\"Full Data or Diet: \")\n","    depth = int(input(\"Depth for Empty Tuples: \"))\n","    if full_or_diet == \"diet\":\n","        model_seed = int(input(\"Trainer Seed (0 or 42): \"))\n","        random.seed(model_seed)\n","\n","        for element in element_key_list[inference_task_name]:\n","            prompts[inference_task_name]['step2'][element] = [random.choice(prompts[inference_task_name]['step2'][element])]\n","\n","        train_inputs, train_targets = get_transformed_io(f\"{parent_directory}{inference_task_name}/{inference_data_name}/train.txt\", inference_task_name, step=2, final_gold_output=False)\n","        dev_inputs, dev_targets = get_transformed_io(f\"{parent_directory}{inference_task_name}/{inference_data_name}/dev.txt\", inference_task_name, step=2, final_gold_output=False)\n","        test_targets = get_transformed_io(f\"{parent_directory}{inference_task_name}/{inference_data_name}/test.txt\", inference_task_name, step=2, final_gold_output=True)\n","        data_step2[f\"{inference_task_name}-{inference_data_name}\"] = [[train_inputs, train_targets], [dev_inputs, dev_targets], [test_targets]]\n","\n","    inference(model_path_step1, model_path_step2, inference_task_name, inference_data_name, full_or_diet, depth)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if full_or_diet_or_low == \"low\":\n","    random.seed(data_seed)\n","    \n","    data_step1 = {}\n","    train_inputs, train_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/train.txt\", train_task_name, step=1, final_gold_output=False, seed=data_seed, percentage=percentage/100)\n","    dev_inputs, dev_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/dev.txt\", train_task_name, step=1, final_gold_output=False, seed=data_seed, percentage=percentage/100)\n","    test_inputs, test_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/test.txt\", train_task_name, step=1, final_gold_output=False)\n","    data_step1[f\"{train_task_name}-{train_data_name}\"] = [[train_inputs, train_targets], [dev_inputs, dev_targets], [test_inputs, test_targets]]\n","\n","    data_step2 = {}\n","    train_inputs, train_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/train.txt\", train_task_name, step=2, final_gold_output=False, seed=data_seed, percentage=percentage/100)\n","    dev_inputs, dev_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/dev.txt\", train_task_name, step=2, final_gold_output=False, seed=data_seed, percentage=percentage/100)\n","    test_targets = get_transformed_io(f\"{parent_directory}{train_task_name}/{train_data_name}/test.txt\", train_task_name, step=2, final_gold_output=True)\n","    data_step2[f\"{train_task_name}-{train_data_name}\"] = [[train_inputs, train_targets], [dev_inputs, dev_targets], [test_targets]] "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)\n","\n","whole_related_data = globals()[f\"data_step{step}\"][f\"{train_task_name}-{train_data_name}\"]\n","input_max_length = max([len(tokenizer.tokenize(data)) for data in (whole_related_data[0][0]+whole_related_data[1][0])])\n","target_max_length = max([len(tokenizer.tokenize(data)) for data in (whole_related_data[0][1]+whole_related_data[1][1])])\n","\n","def init_args(epoch):\n","    args_step1 = types.SimpleNamespace(\n","        learning_rate=3e-4,\n","        train_batch_size=16,\n","        eval_batch_size=8,\n","        output_dir='/kaggle/tmp',\n","        num_train_epochs=epoch, # Default (full) 15\n","    )\n","    args_step2 = types.SimpleNamespace(\n","        learning_rate=1e-4, # For ASTE (R16) and TASD (R16) full, learning_rate = 2e-4, epoch = 15\n","        train_batch_size=16,\n","        eval_batch_size=8,\n","        output_dir='/kaggle/tmp',\n","        num_train_epochs=epoch, # Default (full) 20\n","    )\n","    return args_step1, args_step2\n","\n","args_step1, args_step2 = init_args(epoch)\n","if step == 1:\n","    args = args_step1\n","elif step == 2:\n","    args = args_step2\n","print(input_max_length)\n","print(target_max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = pd.DataFrame({\"input\": globals()[f\"data_step{step}\"][f\"{train_task_name}-{train_data_name}\"][0][0], \"target\": globals()[f\"data_step{step}\"][f\"{train_task_name}-{train_data_name}\"][0][1]})\n","val_df = pd.DataFrame({\"input\": globals()[f\"data_step{step}\"][f\"{train_task_name}-{train_data_name}\"][1][0], \"target\": globals()[f\"data_step{step}\"][f\"{train_task_name}-{train_data_name}\"][1][1]})\n","train_data = Dataset.from_dict({\"input\": train_df[\"input\"], \"target\": train_df[\"target\"]})\n","val_data = Dataset.from_dict({\"input\": val_df[\"input\"], \"target\": val_df[\"target\"]})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert_examples_to_features(example_batch):\n","    global input_max_length\n","    global target_max_length\n","    input_texts = example_batch[\"input\"]\n","    target_texts = example_batch[\"target\"]\n","\n","    input_encodings = tokenizer(input_texts, padding=\"max_length\", truncation=True, max_length=input_max_length)\n","    target_encodings = tokenizer(target_texts, padding=\"max_length\", truncation=True, max_length=target_max_length)\n","\n","    return {\n","        'input_ids': input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }\n","\n","train_pt = train_data.map(convert_examples_to_features, batched=True)\n","val_pt = val_data.map(convert_examples_to_features, batched=True)\n","\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer_args = TrainingArguments(\n","    output_dir = args.output_dir,\n","    num_train_epochs = args.num_train_epochs,\n","    learning_rate = args.learning_rate,\n","    per_device_train_batch_size = args.train_batch_size,\n","    per_device_eval_batch_size = args.eval_batch_size,\n","    evaluation_strategy = \"epoch\",\n","    logging_strategy = \"epoch\",\n","    fp16 = True,\n","    seed = model_seed\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=trainer_args,\n","    tokenizer=tokenizer,\n","    data_collator=seq2seq_data_collator,\n","    train_dataset=train_pt,\n","    eval_dataset=val_pt\n",")\n","\n","torch.cuda.empty_cache()\n","\n","trainer.train()\n","\n","trainer.save_model(\"/kaggle/working/\")\n","\n","tokenizer.save_pretrained(\"/kaggle/working/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!huggingface-cli login --token {huggingface_token}\n","!huggingface-cli repo create {repo_name} --type model -y\n","finetuned_model = AutoModelForSeq2SeqLM.from_pretrained('/kaggle/working/')\n","finetuned_model.push_to_hub(repo_name)\n","tokenizer.push_to_hub(repo_name)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3748019,"sourceId":6486621,"sourceType":"datasetVersion"},{"datasetId":4147585,"sourceId":7176958,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"","name":""},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":4}
